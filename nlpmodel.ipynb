{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\movin\\data-x-team-project\\Tagged Photos' # csv file path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "df = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_, index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "df = pd.concat(list_, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fileName</th>\n",
       "      <th>Labels</th>\n",
       "      <th>FaceDetails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Facebook/ENFJ/1000006876806379.jpg</td>\n",
       "      <td>[{'Name': 'Human', 'Confidence': 99.2957839965...</td>\n",
       "      <td>[{'BoundingBox': {'Width': 0.11999999731779099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Facebook/ENFJ/1001091583356351.jpg</td>\n",
       "      <td>[{'Name': 'Art', 'Confidence': 52.856147766113...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Facebook/ENFJ/1001328126675771.jpg</td>\n",
       "      <td>[{'Name': 'People', 'Confidence': 99.012985229...</td>\n",
       "      <td>[{'BoundingBox': {'Width': 0.4146634638309479,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Facebook/ENFJ/10100163853254202.jpg</td>\n",
       "      <td>[{'Name': 'Art', 'Confidence': 91.370552062988...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Facebook/ENFJ/10100238407492499.jpg</td>\n",
       "      <td>[{'Name': 'Human', 'Confidence': 99.3081130981...</td>\n",
       "      <td>[{'BoundingBox': {'Width': 0.6088888645172119,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             fileName  \\\n",
       "0           0   Facebook/ENFJ/1000006876806379.jpg   \n",
       "1           1   Facebook/ENFJ/1001091583356351.jpg   \n",
       "2           2   Facebook/ENFJ/1001328126675771.jpg   \n",
       "3           3  Facebook/ENFJ/10100163853254202.jpg   \n",
       "4           4  Facebook/ENFJ/10100238407492499.jpg   \n",
       "\n",
       "                                              Labels  \\\n",
       "0  [{'Name': 'Human', 'Confidence': 99.2957839965...   \n",
       "1  [{'Name': 'Art', 'Confidence': 52.856147766113...   \n",
       "2  [{'Name': 'People', 'Confidence': 99.012985229...   \n",
       "3  [{'Name': 'Art', 'Confidence': 91.370552062988...   \n",
       "4  [{'Name': 'Human', 'Confidence': 99.3081130981...   \n",
       "\n",
       "                                         FaceDetails  \n",
       "0  [{'BoundingBox': {'Width': 0.11999999731779099...  \n",
       "1                                                 []  \n",
       "2  [{'BoundingBox': {'Width': 0.4146634638309479,...  \n",
       "3                                                 []  \n",
       "4  [{'BoundingBox': {'Width': 0.6088888645172119,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15997"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the personality for every photo\n",
    "personality_list = []\n",
    "for i in range(len(df.index)):\n",
    "    personality_list.append(df['fileName'][i][9:13])\n",
    "len(personality_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ISTP',\n",
       " 'ISTP',\n",
       " 'ISTP',\n",
       " 'ISTP',\n",
       " 'ISTP',\n",
       " 'ISTP',\n",
       " 'ISTP',\n",
       " 'ISTP',\n",
       " 'ISTP',\n",
       " 'ISTP']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_list[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fileName</th>\n",
       "      <th>Labels</th>\n",
       "      <th>FaceDetails</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Facebook/ENFJ/1000006876806379.jpg</td>\n",
       "      <td>[{'Name': 'Human', 'Confidence': 99.2957839965...</td>\n",
       "      <td>[{'BoundingBox': {'Width': 0.11999999731779099...</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Facebook/ENFJ/1001091583356351.jpg</td>\n",
       "      <td>[{'Name': 'Art', 'Confidence': 52.856147766113...</td>\n",
       "      <td>[]</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Facebook/ENFJ/1001328126675771.jpg</td>\n",
       "      <td>[{'Name': 'People', 'Confidence': 99.012985229...</td>\n",
       "      <td>[{'BoundingBox': {'Width': 0.4146634638309479,...</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Facebook/ENFJ/10100163853254202.jpg</td>\n",
       "      <td>[{'Name': 'Art', 'Confidence': 91.370552062988...</td>\n",
       "      <td>[]</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Facebook/ENFJ/10100238407492499.jpg</td>\n",
       "      <td>[{'Name': 'Human', 'Confidence': 99.3081130981...</td>\n",
       "      <td>[{'BoundingBox': {'Width': 0.6088888645172119,...</td>\n",
       "      <td>ENFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             fileName  \\\n",
       "0           0   Facebook/ENFJ/1000006876806379.jpg   \n",
       "1           1   Facebook/ENFJ/1001091583356351.jpg   \n",
       "2           2   Facebook/ENFJ/1001328126675771.jpg   \n",
       "3           3  Facebook/ENFJ/10100163853254202.jpg   \n",
       "4           4  Facebook/ENFJ/10100238407492499.jpg   \n",
       "\n",
       "                                              Labels  \\\n",
       "0  [{'Name': 'Human', 'Confidence': 99.2957839965...   \n",
       "1  [{'Name': 'Art', 'Confidence': 52.856147766113...   \n",
       "2  [{'Name': 'People', 'Confidence': 99.012985229...   \n",
       "3  [{'Name': 'Art', 'Confidence': 91.370552062988...   \n",
       "4  [{'Name': 'Human', 'Confidence': 99.3081130981...   \n",
       "\n",
       "                                         FaceDetails Personality  \n",
       "0  [{'BoundingBox': {'Width': 0.11999999731779099...        ENFJ  \n",
       "1                                                 []        ENFJ  \n",
       "2  [{'BoundingBox': {'Width': 0.4146634638309479,...        ENFJ  \n",
       "3                                                 []        ENFJ  \n",
       "4  [{'BoundingBox': {'Width': 0.6088888645172119,...        ENFJ  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the personality column to dataframe\n",
    "se = pd.Series(personality_list)\n",
    "df['Personality'] = se.values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ENFJ\n",
       "1        ENFJ\n",
       "2        ENFJ\n",
       "3        ENFJ\n",
       "4        ENFJ\n",
       "5        ENFJ\n",
       "6        ENFJ\n",
       "7        ENFJ\n",
       "8        ENFJ\n",
       "9        ENFJ\n",
       "10       ENFJ\n",
       "11       ENFJ\n",
       "12       ENFJ\n",
       "13       ENFJ\n",
       "14       ENFJ\n",
       "15       ENFJ\n",
       "16       ENFJ\n",
       "17       ENFJ\n",
       "18       ENFJ\n",
       "19       ENFJ\n",
       "20       ENFJ\n",
       "21       ENFJ\n",
       "22       ENFJ\n",
       "23       ENFJ\n",
       "24       ENFJ\n",
       "25       ENFJ\n",
       "26       ENFJ\n",
       "27       ENFJ\n",
       "28       ENFJ\n",
       "29       ENFJ\n",
       "         ... \n",
       "15967    ISTP\n",
       "15968    ISTP\n",
       "15969    ISTP\n",
       "15970    ISTP\n",
       "15971    ISTP\n",
       "15972    ISTP\n",
       "15973    ISTP\n",
       "15974    ISTP\n",
       "15975    ISTP\n",
       "15976    ISTP\n",
       "15977    ISTP\n",
       "15978    ISTP\n",
       "15979    ISTP\n",
       "15980    ISTP\n",
       "15981    ISTP\n",
       "15982    ISTP\n",
       "15983    ISTP\n",
       "15984    ISTP\n",
       "15985    ISTP\n",
       "15986    ISTP\n",
       "15987    ISTP\n",
       "15988    ISTP\n",
       "15989    ISTP\n",
       "15990    ISTP\n",
       "15991    ISTP\n",
       "15992    ISTP\n",
       "15993    ISTP\n",
       "15994    ISTP\n",
       "15995    ISTP\n",
       "15996    ISTP\n",
       "Name: Personality, Length: 15997, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Personality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to get tags for each photo\n",
    "def get_tag(astring):\n",
    "    split_list = re.split(': |,',astring)\n",
    "    taglist = []\n",
    "    for i in range(0,len(split_list)//4):\n",
    "        taglist.append(split_list[4*i+1])\n",
    "    return(taglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'Name': 'Human', 'Confidence': 99.29578399658203}, {'Name': 'People', 'Confidence': 99.29878234863281}, {'Name': 'Person', 'Confidence': 99.29878234863281}, {'Name': 'Apparel', 'Confidence': 75.07823181152344}, {'Name': 'Clothing', 'Confidence': 75.07823181152344}, {'Name': 'Maillot', 'Confidence': 60.394203186035156}, {'Name': 'Female', 'Confidence': 60.05233383178711}, {'Name': 'Dress', 'Confidence': 51.23127746582031}, {'Name': 'Bra', 'Confidence': 50.790958404541016}, {'Name': 'Lingerie', 'Confidence': 50.790958404541016}, {'Name': 'Underwear', 'Confidence': 50.790958404541016}]\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15997"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the tags\n",
    "tagdict = {}\n",
    "for i in range(len(df.index)):\n",
    "    tagdict[df['fileName'][i]] = get_tag(df['Labels'][i])\n",
    "len(tagdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get set of tags\n",
    "tagset = set()\n",
    "for key in tagdict:\n",
    "    for value in tagdict[key]:\n",
    "        tagset.add(value)\n",
    "len(tagset) # in total 1797 different tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15997"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taglist = []\n",
    "for key in tagdict:\n",
    "    taglist.append(tagdict[key])\n",
    "len(taglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'Human'\",\n",
       " \"'People'\",\n",
       " \"'Person'\",\n",
       " \"'Apparel'\",\n",
       " \"'Clothing'\",\n",
       " \"'Maillot'\",\n",
       " \"'Female'\",\n",
       " \"'Dress'\",\n",
       " \"'Bra'\",\n",
       " \"'Lingerie'\",\n",
       " \"'Underwear'\"]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taglist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get rid of extra \"\"\n",
    "for i in range(len(taglist)):\n",
    "    for j in range(len(taglist[i])):\n",
    "        taglist[i][j] = taglist[i][j][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Human',\n",
       " 'People',\n",
       " 'Person',\n",
       " 'Apparel',\n",
       " 'Clothing',\n",
       " 'Maillot',\n",
       " 'Female',\n",
       " 'Dress',\n",
       " 'Bra',\n",
       " 'Lingerie',\n",
       " 'Underwear']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taglist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join each word of an element of taglist into a string\n",
    "for i in range(len(taglist)):\n",
    "    taglist[i] = ' '.join(word for word in taglist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human People Person Apparel Clothing Maillot Female Dress Bra Lingerie Underwear'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taglist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentiment classification w/ scikit-learn, feature vector, bag of words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics # for confusion matrix, accuracy score etc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the training set and testing set\n",
    "x_train, x_test, y_train, y_test = train_test_split(taglist, df['Personality'], random_state=0, test_size=.2)\n",
    "\n",
    "# CountVectorize\n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=None, preprocessor=None, stop_words=None, max_features=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 159 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=2000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Transform the text data to feature\n",
    "# Only fit training data (to mimic real world)\n",
    "\n",
    "vectorizer.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abies', 'abyssinian', 'acanthaceae', 'accessories', 'accipiter', 'activities', 'adapter', 'adorable', 'adventure', 'aerial']\n"
     ]
    }
   ],
   "source": [
    "# Check that it worked, \n",
    "# now we have fitted a model that can transform features\n",
    "# to sparse matrix representation\n",
    "\n",
    "print(vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bag = vectorizer.transform(x_train) #transform to a feature matrix\n",
    "test_bag = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12797, 1668)\n",
      "(3200, 1668)\n"
     ]
    }
   ],
   "source": [
    "# 15997 photos, 1668 feartures\n",
    "print(train_bag.toarray().shape)\n",
    "print(test_bag.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 189)\t1\n",
      "  (0, 805)\t1\n",
      "  (0, 1074)\t1\n",
      "  (0, 1129)\t1\n",
      "  (0, 1137)\t1\n",
      "  (0, 1196)\t1\n",
      "  (0, 1290)\t1\n",
      "  (0, 1320)\t1\n",
      "  (0, 1383)\t1\n",
      "  (1, 374)\t1\n",
      "  (1, 380)\t1\n",
      "  (1, 805)\t1\n",
      "  (1, 827)\t1\n",
      "  (1, 1078)\t1\n",
      "  (1, 1129)\t1\n",
      "  (1, 1137)\t1\n",
      "  (1, 1445)\t1\n",
      "  (1, 1570)\t1\n",
      "  (2, 31)\t1\n",
      "  (2, 32)\t1\n",
      "  (2, 213)\t1\n",
      "  (2, 214)\t1\n",
      "  (2, 409)\t1\n",
      "  (2, 586)\t1\n",
      "  (2, 591)\t1\n",
      "  :\t:\n",
      "  (12795, 132)\t1\n",
      "  (12795, 180)\t1\n",
      "  (12795, 356)\t1\n",
      "  (12795, 586)\t1\n",
      "  (12795, 696)\t1\n",
      "  (12795, 702)\t1\n",
      "  (12795, 739)\t1\n",
      "  (12795, 805)\t1\n",
      "  (12795, 859)\t1\n",
      "  (12795, 1129)\t1\n",
      "  (12795, 1137)\t1\n",
      "  (12795, 1196)\t1\n",
      "  (12795, 1320)\t1\n",
      "  (12795, 1450)\t1\n",
      "  (12796, 12)\t1\n",
      "  (12796, 586)\t1\n",
      "  (12796, 696)\t1\n",
      "  (12796, 702)\t1\n",
      "  (12796, 739)\t1\n",
      "  (12796, 741)\t1\n",
      "  (12796, 805)\t1\n",
      "  (12796, 1129)\t1\n",
      "  (12796, 1137)\t1\n",
      "  (12796, 1320)\t1\n",
      "  (12796, 1450)\t1\n"
     ]
    }
   ],
   "source": [
    "type(train_bag) # sparse matrix representation\n",
    "\n",
    "print(train_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classify with Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Initialize a Random Forest classifier with 50 trees\n",
    "# hyperparameter n_estimators always set in instantiation\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the target variable\n",
    "\n",
    "forest = forest.fit(train_bag, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "\n",
    "train_predictions = forest.predict(train_bag)\n",
    "valid_predictions = forest.predict(test_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6454637805735719"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "metrics.accuracy_score(y_train,train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049375000000000002"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "metrics.accuracy_score(y_test,valid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9, 12, 11, 15, 11, 13, 14, 12, 14,  5, 14, 21, 10, 14, 13, 16],\n",
       "       [12, 12,  6, 13,  7, 16, 12, 16, 18, 16, 17,  6,  7, 15,  9, 14],\n",
       "       [15, 11,  6, 14, 10, 17, 16,  5, 10, 14, 12, 17, 14,  7,  6, 12],\n",
       "       [10, 12, 11,  9, 10,  8,  4, 11, 22, 10,  7, 22, 12, 10,  8, 15],\n",
       "       [ 7, 10, 17,  6,  9, 17, 19,  9, 13, 12, 11, 16, 17,  8, 12, 12],\n",
       "       [10, 19, 12, 11, 20, 12, 13, 20,  5, 13, 13, 12,  7, 14, 12, 11],\n",
       "       [12,  8, 14, 12, 24, 10,  9, 21, 13,  7, 15,  8,  9, 10,  7, 10],\n",
       "       [16, 19, 17,  8, 16, 22, 17, 10, 10,  9,  8, 19, 16, 15, 10, 13],\n",
       "       [ 4, 20,  8, 17, 15,  9, 12, 12, 13, 19, 17,  9, 14,  9, 19, 10],\n",
       "       [13, 11, 10,  9, 11, 11, 13, 12, 18,  7, 17, 17,  9, 13,  7, 13],\n",
       "       [12, 18, 11,  8, 16, 10, 11,  5, 17, 13, 13, 18, 17,  9,  8, 11],\n",
       "       [10, 13, 17, 12, 13, 21,  7,  7, 19, 19, 12, 12, 20, 11,  8, 17],\n",
       "       [11, 16, 10, 11, 11, 14,  9,  9, 13,  9, 11, 13, 12, 17, 11,  8],\n",
       "       [10, 10, 13,  9, 18, 11, 13, 10, 13, 11,  7, 11, 20,  8, 19, 26],\n",
       "       [14, 11, 13, 10, 22, 17, 13,  9, 12,  9, 16, 13, 12, 15,  8, 16],\n",
       "       [11, 11, 15, 14, 13, 12, 15,  8, 11, 12, 10, 15, 13, 23, 11,  9]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "# Is the number of False Positives and True negatives approx 50/50?\n",
    "metrics.confusion_matrix(y_test,valid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_predictions==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
